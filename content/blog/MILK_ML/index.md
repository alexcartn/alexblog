---
title: Peut-on prÃ©dire la qualitÃ© du lait avec le machine learning ?
weight: 
subtitle: Un projet pratique dâ€™analyse de donnÃ©es et de classification
excerpt: Dans cet article, nous explorons comment les algorithmes de machine learning peuvent Ãªtre utilisÃ©s pour prÃ©dire automatiquement la qualitÃ© du lait, Ã  partir de simples mesures physico-chimiques et sensorielles.Ã€ lâ€™aide dâ€™un jeu de donnÃ©es issu de Kaggle, nous analysons les variables clÃ©s, construisons un modÃ¨le prÃ©dictif, et montrons comment ce type dâ€™approche peut optimiser les contrÃ´les qualitÃ© industriels.
date: 2025-07-31
draft: false
tags: 
categories: 
layout: single
---

# Introduction et contexte du machine learning â€” le workflow

Lâ€™objectif du machine learning, câ€™est **de ne pas avoir besoin de connaÃ®tre toutes les Ã©quations scientifiques** qui dÃ©crivent un systÃ¨me.  
Avec un modÃ¨le physique classique, on part des lois (mÃ©caniques, chimiquesâ€¦) â†’ on prend les entrÃ©es â†’ on calcule les sorties.
Mais parfois, ces lois sont **trop complexes** ou **impossibles Ã  Ã©crire prÃ©cisÃ©ment**.

ğŸ‘‰ Le **machine learning** propose une autre approche :

> Â« Et si, au lieu de connaÃ®tre les Ã©quations, on apprenait directement des exemples ? Â»

### ğŸ” Un changement de logique

- **ModÃ¨le classique** : on connaÃ®t les lois â†’ on calcule la sortie Ã  partir des entrÃ©es.
    
- **Machine learning** : on donne **plein dâ€™exemples dâ€™entrÃ©es et de sorties**, et le modÃ¨le apprend **la rÃ¨gle gÃ©nÃ©rale** tout seul.

### ğŸ¯ PrÃ©cision du modÃ¨le : lâ€™accuracy

Une fois entraÃ®nÃ©, le modÃ¨le doit Ãªtre capable de **prÃ©dire une sortie correcte** Ã  partir dâ€™une **nouvelle entrÃ©e quâ€™il nâ€™a jamais vue**.

Mais attention : un modÃ¨le nâ€™est jamais parfait !

Par exemple, un modÃ¨le avec **80â€¯% de prÃ©cision** veut dire quâ€™il donne la bonne rÃ©ponse 8 fois sur 10â€¦ mais se trompe encore dans 20â€¯% des cas.

> **Lâ€™objectif ?** Obtenir la **meilleure prÃ©cision possible** (accuracy), sans surcharger inutilement le modÃ¨le.

Le but est simple : **maximiser cette prÃ©cision**.  
Et pour Ã§a, deux leviers principaux :

- **Plus de donnÃ©es pertinentes** : capteurs, mesures, signaux fiables â†’ plus de matiÃ¨re Ã  apprendre.
- **Un modÃ¨le plus adaptÃ©** : parfois un modÃ¨le plus complexe (mais pas trop !) permet dâ€™amÃ©liorer les performances.

### ğŸ§  Typologie de modÃ¨les

Le choix du modÃ¨le dÃ©pend :

- du type de sortie attendue (ex : une **classe** â†’ modÃ¨le de classification ; une **valeur continue** â†’ rÃ©gression),
    
- et du type dâ€™apprentissage :
    
    - **supervisÃ©** : on connaÃ®t les rÃ©ponses pendant lâ€™apprentissage,
        
    - **non supervisÃ©** : on cherche Ã  dÃ©couvrir des structures dans les donnÃ©es (ex : regroupements).
        
![Pasted image 20250730155424.png](ML.png)


### ğŸ” Le workflow du machine learning, Ã©tape par Ã©tape

Quel que soit le problÃ¨me, la **dÃ©marche reste la mÃªme** :

1. **Collecte des donnÃ©es** : capteurs, sondes, bases existantes
    
2. **Nettoyage et prÃ©paration** : vÃ©rifier, convertir, formater les donnÃ©es
    
3. **Choix du type dâ€™apprentissage** :
    
    - _SupervisÃ©_ : on a les rÃ©ponses (ex : qualitÃ© du lait)
        
    - _Non supervisÃ©_ : on nâ€™a pas les rÃ©ponses (ex : grouper des profils similaires)
        
4. **EntraÃ®nement du modÃ¨le** : on lui montre les exemples et il apprend
    
5. **Ã‰valuation** : on vÃ©rifie sur des donnÃ©es nouvelles sâ€™il se dÃ©brouille bien
    
6. **DÃ©ploiement** : sur le cloud, dans un appareil embarquÃ©, ou intÃ©grÃ© dans un process industriel

![Pasted image 20250730155215.png](workflow.png)


---

<div style="text-align: center;">

**Ne ratez plus aucune nouveautÃ© : abonnez-vous Ã  la newsletter ğŸ‘‹**

<form action="https://formspree.io/f/xwpkgwjd" method="POST" style="display:inline-block;">

Â  <label for="email" style="display:block; margin-bottom:0.5rem;">Votre email :</label>
Â  <input type="email" name="email" id="email" placeholder="exemple@domaine.com" required style="margin-bottom:0.5rem;">

Â  <button type="submit">Envoyer</button>
</form>
</div>

---


# PrÃ©diction de la qualitÃ© du lait avec le machine learning

Pour illustrer concrÃ¨tement la mÃ©thode du machine learning, prenons un **cas pratique**.  
Le site [Kaggle](https://www.kaggle.com) propose des **jeux de donnÃ©es gratuits** pour s'entraÃ®ner. Ici, nous allons utiliser un dataset qui contient des mesures sur des Ã©chantillons de lait, et essayer de prÃ©dire automatiquement leur **qualitÃ©**.

> ğŸ”§ Le projet est rÃ©alisÃ© en **Python**, avec la bibliothÃ¨que **Scikit-learn**, (le lien avec le code source est disponible en bas de lâ€™article).


ğŸ¯ **Objectif**
Ce projet a pour but de **prÃ©dire automatiquement la qualitÃ© du lait** Ã  partir de mesures physico-chimiques et sensorielles, en utilisant des algorithmes de machine learning supervisÃ©.

Lâ€™objectif final est multiple : 

- âœ… **Fiabiliser et automatiser les contrÃ´les qualitÃ©** : en remplaÃ§ant ou en complÃ©tant les inspections manuelles, souvent subjectives et coÃ»teuses, par un systÃ¨me dâ€™aide Ã  la dÃ©cision rapide, rÃ©pÃ©table et objectivable.
- ğŸ’¡ **Optimiser les processus industriels** : en dÃ©tectant en temps rÃ©el les dÃ©rives de production (pH, goÃ»t, turbiditÃ©, etc.), le modÃ¨le permet dâ€™anticiper les non-conformitÃ©s, dâ€™ajuster les paramÃ¨tres de fabrication ou de trier les lots efficacement.
- ğŸ’° **RÃ©duire les coÃ»ts de production et les pertes**, en identifiant prÃ©cocement les lots non conformes ou dÃ©gradÃ©s, ce qui permet dâ€™agir rapidement (ajustement du processus, Ã©limination ou revalorisation des lots impropres Ã  la consommation).

ğŸ“Š Ã€ propos du dataset :

Les donnÃ©es sont disponibles dans un simple fichier **CSV** (`milknew.csv`)
Le jeu de donnÃ©es contient 1059 Ã©chantillons de lait, collectÃ©s manuellement, chacun dÃ©crit par 7 variables indÃ©pendantes. 

**RÃ©sumÃ© des variables (features)**

|**Variable**|**Description**|**Valeurs possibles**|
|---|---|---|
|`pH`|Mesure de lâ€™aciditÃ© ou de lâ€™alcalinitÃ© du lait. Influence la fraÃ®cheur et la stabilitÃ©.|Valeurs continues entre 3.0 et 9.5|
|`Temperature`|TempÃ©rature de lâ€™Ã©chantillon lors de lâ€™analyse. Impacte la qualitÃ© microbiologique.|Valeurs continues entre 34Â°C et 90Â°C|
|`Taste`|Ã‰valuation sensorielle du goÃ»t du lait, rÃ©alisÃ©e par un testeur ou un capteur.|0 = mauvais goÃ»t, 1 = bon goÃ»t|
|`Odor`|Ã‰valuation olfactive, rÃ©vÃ©lant la fraÃ®cheur ou dâ€™Ã©ventuelles altÃ©rations.|0 = mauvaise odeur, 1 = bonne odeur|
|`Fat`|Teneur en matiÃ¨re grasse, un indicateur clÃ© pour la texture et la valeur nutritionnelle.|0 = faible, 1 = Ã©levÃ©e|
|`Turbidity`|Mesure de la turbiditÃ© (opacitÃ©), souvent liÃ©e Ã  des particules indÃ©sirables.|0 = limpide, 1 = trouble|
|`Colour`|Indication de la couleur du lait, influencÃ©e par la composition ou lâ€™oxydation.|Valeurs entiÃ¨res entre 240 et 255|

La **variable cible** `Grade` indique la qualitÃ© du lait :

- `Low` â†’ mauvaise qualitÃ©
    
- `Medium` â†’ qualitÃ© moyenne
    
- `High` â†’ bonne qualitÃ©

ğŸ§ª Ces classes ont Ã©tÃ© dÃ©terminÃ©es en fonction de seuils sur les variables dÃ©crites ci-dessus. Certaines dâ€™entre elles sont binarisÃ©es selon des critÃ¨res experts (ex. : goÃ»t acceptable = 1), tandis que dâ€™autres (comme le pH ou la tempÃ©rature) conservent leur valeur continue.
## Exploration des donnÃ©es 

ğŸ§¹ VÃ©rification et nettoyage des donnÃ©es

Nous commenÃ§ons par une **analyse exploratoire du fichier CSV** fourni afin de :

- vÃ©rifier lâ€™intÃ©gritÃ© du jeu de donnÃ©es (prÃ©sence de donnÃ©es manquantes),
- identifier le type de donnÃ©es associÃ© Ã  chaque variable.

**AperÃ§u des 5 premiÃ¨res lignes**


|   | pH  | Temprature | Taste | Odor | Fat | Turbidity | Colour | Grade  |
| - | --- | ---------- | ----- | ---- | --- | --------- | ------ | ------ |
| 0 | 6.6 | 35         | 1     | 0    | 1   | 0         | 254    | high   |
| 1 | 6.6 | 36         | 0     | 1    | 0   | 1         | 253    | high   |
| 2 | 8.5 | 70         | 1     | 1    | 1   | 1         | 246    | low    |
| 3 | 9.5 | 34         | 1     | 1    | 0   | 1         | 255    | low    |
| 4 | 6.6 | 37         | 0     | 0    | 0   | 0         | 255    | medium |

ğŸ“‹ **RÃ©sumÃ© des types de donnÃ©es :**

| # | Colonne        | Valeurs non nulles | Type    |
| - | -------------- | ------------------ | ------- |
| 0 | **pH**         | 1059               | float64 |
| 1 | **Temprature** | 1059               | int64   |
| 2 | **Taste**      | 1059               | int64   |
| 3 | **Odor**       | 1059               | int64   |
| 4 | **Fat**        | 1059               | int64   |
| 5 | **Turbidity**  | 1059               | int64   |
| 6 | **Colour**     | 1059               | int64   |
| 7 | **Grade**      | 1059               | object  |


ğŸ‘‰ **RÃ©sultat de lâ€™analyse initiale :**

- Le dataset contient bien **1059 Ã©chantillons**, sans **aucune donnÃ©e manquante**.
- La typologie des colonnes est cohÃ©rente :
    - Les **donnÃ©es continues** (`pH`, `Temperature`) sont de type `float64` ou `int64` selon la prÃ©cision,
    - Les **variables binaires** (`Taste`, `Odor`, `Fat`, `Turbidity`) sont de type `int64`,
    - La variable cible `Grade` est de type `object` (catÃ©gorielle, texte)


ğŸ” Aucune transformation nâ€™est nÃ©cessaire Ã  ce stade en ce qui concerne les types de donnÃ©es ou la gestion des valeurs manquantes. Le dataset est donc prÃªt Ã  Ãªtre utilisÃ© pour lâ€™Ã©tape de **prÃ©traitement**.

## Statistiques descriptives

Avant de construire un modÃ¨le de machine learning, il est essentiel de **comprendre la structure et la distribution des donnÃ©es**.  
Nous commenÃ§ons donc par une analyse descriptive pour identifier les tendances gÃ©nÃ©rales et les relations entre les variables.

Cette phase se dÃ©compose en trois Ã©tapes :

1. **Analyse des valeurs centrales** (moyenne, mÃ©diane, quartiles) pour visualiser la **rÃ©partition des variables** et dÃ©tecter dâ€™Ã©ventuelles asymÃ©tries ou valeurs extrÃªmes.
    
2. **Analyse univariÃ©e** Ã  lâ€™aide de **boxplots**, pour observer la dispersion et repÃ©rer les outliers.
    
3. **Analyse bivariÃ©e** via une **matrice de corrÃ©lation**, afin dâ€™Ã©valuer les relations linÃ©aires entre les variables et identifier les Ã©ventuelles redondances.
    

Ces Ã©lÃ©ments nous permettront dâ€™**anticiper la pertinence de chaque variable dans le modÃ¨le prÃ©dictif**, et dâ€™orienter la phase de sÃ©lection de features.

### RÃ©sumÃ© des statistiques descriptives


|       | pH       | Temprature | Taste    | Odor     | Fat      | Turbidity | Colour   |
| ----- | -------- | ---------- | -------- | -------- | -------- | --------- | -------- |
| count | 1059.000 | 1059.000   | 1059.000 | 1059.000 | 1059.000 | 1059.000  | 1059.000 |
| mean  | 6.630    | 44.227     | 0.547    | 0.432    | 0.671    | 0.491     | 251.840  |
| std   | 1.400    | 10.098     | 0.498    | 0.496    | 0.470    | 0.500     | 4.307    |
| min   | 3.000    | 34.000     | 0.000    | 0.000    | 0.000    | 0.000     | 240.000  |
| 25%   | 6.500    | 38.000     | 0.000    | 0.000    | 0.000    | 0.000     | 250.000  |
| 50%   | 6.700    | 41.000     | 1.000    | 0.000    | 1.000    | 0.000     | 255.000  |
| 75%   | 6.800    | 45.000     | 1.000    | 1.000    | 1.000    | 1.000     | 255.000  |
| max   | 9.500    | 90.000     | 1.000    | 1.000    | 1.000    | 1.000     | 255.000  |

![[Pasted image 20250730161934.png]](histo.png)


- âœ… **Aucune donnÃ©e manquante** : toutes les colonnes comptent 1059 valeurs.
- ğŸ“‰ **pH** : moyenne autour de 6.6, valeurs extrÃªmes entre 3.0 et 9.5 â€” quelques cas atypiques possibles.
- ğŸŒ¡ **TempÃ©rature** : moyenne Ã  44â€¯Â°C, avec des pointes jusquâ€™Ã  90â€¯Â°C â€” probablement des cas particuliers ou expÃ©rimentaux.
- ğŸ¨ **Couleur** : trÃ¨s homogÃ¨ne (moyenne Ã  251.8), majoritÃ© des Ã©chantillons proches du blanc standard (255).

**Variables binaires :**

- ğŸ˜‹ **GoÃ»t (`Taste`)** : environ 55â€¯% des Ã©chantillons sont jugÃ©s bons.
- ğŸ‘ƒ **Odeur (`Odor`)** : plus de la moitiÃ© prÃ©sentent une odeur mauvaise.
- ğŸ§ˆ **MatiÃ¨re grasse (`Fat`)** : 67â€¯% des Ã©chantillons ont une teneur Ã©levÃ©e.
- ğŸ’§ **TurbiditÃ©** : bien rÃ©partie entre limpide et trouble (valeurs Ã©quilibrÃ©es).

ğŸ§  Ces tendances permettront dâ€™orienter la phase de modÃ©lisation et dâ€™identifier les variables les plus discriminantes pour la prÃ©diction de la qualitÃ©.

### Boxplots par variable â€” _Analyse univariÃ©e_

Ces diagrammes permettent dâ€™analyser la **distribution** de chaque variable et dâ€™identifier les **valeurs aberrantes (outliers)**.

- **pH** : Distribution centrÃ©e autour de 6,6. Quelques outliers vers le bas (< 4) et le haut (> 8.5), Ã  surveiller.
- **Temperature** : MÃ©diane autour de 41-44Â°C. Des outliers Ã©levÃ©s jusquâ€™Ã  90Â°C â†’ Ã©chantillons potentiellement atypiques ou erreurs de saisie.
- **Taste / Odor / Fat / Turbidity** : Variables binaires (0 ou 1), donc reprÃ©sentÃ©es par des barres fines â†’ distribution claire (prÃ©sence/absence).
- **Colour** : Distribution concentrÃ©e vers 255, avec quelques valeurs plus basses (~240), reflÃ©tant une variation de teinte perceptible dans peu dâ€™Ã©chantillons.

ğŸ‘‰ **Conclusion** :

- Peu de variabilitÃ© sur les donnÃ©es binaires (discrÃ¨tes).
- `Temperature` et `pH` nÃ©cessitent une attention particuliÃ¨re pour un Ã©ventuel **traitement des valeurs extrÃªmes**.

![[Pasted image 20250730160622.png]](boxplot.png)

### **Matrice de corrÃ©lation (%)**  (Analyse bivariÃ©e)

Cette heatmap montre les **corrÃ©lations linÃ©aires** entre les variables (coefficient de Pearson) exprimÃ©es en pourcentage.

**ğŸ’¡ CorrÃ©lations significatives :**

- `Odor` est positivement corrÃ©lÃ©e Ã  :
    
    - `Taste` (**32â€¯%**)
    - `Fat` (**31â€¯%**)
    - `Turbidity` (**46â€¯%**)  
        â†’ Une **bonne odeur est souvent associÃ©e Ã  un bon goÃ»t, une forte teneur en graisse et un lait trouble**, ce qui peut reflÃ©ter un lait riche mais non homogÃ©nÃ©isÃ©.

- `Fat` â†” `Taste` : **32â€¯%**  
    â†’ La matiÃ¨re grasse influence positivement la perception du goÃ»t.
- `Fat` â†” `Turbidity` : **33â€¯%**  
    â†’ Plus de matiÃ¨re grasse â†’ lait plus trouble, ce qui est logique.
- `pH` a une faible corrÃ©lation avec toutes les autres variables.  
    â†’ Il varie indÃ©pendamment du reste â†’ **bonne variable discriminante potentielle.**

**ğŸ” CorrÃ©lations faibles / nÃ©gligeables :**

- `Colour` est **peu corrÃ©lÃ©e** aux autres variables.
- `Temperature` nâ€™est pas fortement liÃ©e aux critÃ¨res sensoriels (goÃ»t, odeurâ€¦).

![[Pasted image 20250730161806.png]](correlation.png)

## **RÃ©sumÃ© exploratoire synthÃ©tique**

Lâ€™analyse prÃ©liminaire du jeu de donnÃ©es met en Ã©vidence les points suivants :

- âœ… **DonnÃ©es propres** : 1059 Ã©chantillons, aucune valeur manquante.
    
- ğŸ“‰ **Variables continues** (`pH`, `Temperature`, `Colour`) :
    
    - Quelques **valeurs extrÃªmes** (notamment pour `Temperature` jusquâ€™Ã  90â€¯Â°C).
        
    - `Colour` est trÃ¨s concentrÃ©e autour de 255 â†’ **faible variabilitÃ©**.
        
- ğŸ”¢ **Variables binaires** (`Taste`, `Odor`, `Fat`, `Turbidity`) :
    
    - `Fat` est majoritairement Ã©levÃ©e (67â€¯%),
        
    - `Odor` est plus souvent mauvaise,
        
    - Variables globalement **bien rÃ©parties** entre 0 et 1.
        
- ğŸ“¦ **Boxplots** :
    
    - Confirment les observations ci-dessus,
        
    - Outliers visibles pour `Temperature` et `pH` uniquement.
        
- ğŸ”— **CorrÃ©lations** :
    
    - Relations fortes entre variables sensorielles : `Taste`, `Fat`, `Odor`, `Turbidity`,
        
    - `pH` et `Colour` sont **peu corrÃ©lÃ©s aux autres** â†’ apportent une information indÃ©pendante.

## DÃ©velopper un modÃ¨le prÃ©dictif avec le _machine learning_

Maintenant que nos donnÃ©es sont prÃªtes, voyons **comment crÃ©er un Â« modÃ¨le Â»** qui va apprendre Ã  reconnaÃ®tre la qualitÃ© du lait. Imaginez :

- On montre au modÃ¨le **beaucoup dâ€™exemples** de lait dont on connaÃ®t dÃ©jÃ  la qualitÃ©.
    
- Le modÃ¨le Ã©tudie les mesures (goÃ»t, odeur, pHâ€¦) et repÃ¨re des **motifs**.
    
- Puis, sur un nouvel Ã©chantillon, il prÃ©dit si la qualitÃ© est Â« Low Â», Â« Medium Â» ou Â« High Â».
    

###  Choix du modÃ¨le : la forÃªt dâ€™arbres de dÃ©cision

Dans notre cas, nous utilisons un **apprentissage supervisÃ©**, car nous connaissons la **sortie attendue** : câ€™est un problÃ¨me de **classification**, puisque la sortie est une **classe** (le grade du lait).

Nous avons choisi un algorithme de type **Random Forest** (forÃªt alÃ©atoire dâ€™arbres de dÃ©cision), car il est :

- **robuste** face au bruit dans les donnÃ©es,
    
- **performant** mÃªme sans rÃ©glages poussÃ©s,
    
- et nÃ©cessite **peu d'ajustements** pour obtenir de bons rÃ©sultats.

**ğŸ§  Un arbre de dÃ©cision, câ€™est quoi ?**

On peut le comparer Ã  un petit **organigramme logique** :

> Â« Si la matiÃ¨re grasse > X, alors bonne qualitÃ© ; sinon, vÃ©rifier lâ€™odeurâ€¦ Â»

Chaque **arbre** prend ses propres dÃ©cisions sur la base de critÃ¨res simples.

**ğŸ”§ ParamÃ¨tres choisis**

Par dÃ©faut, pour l'entraÃ®nement, nous avons utilisÃ© **100 arbres** dans la forÃªt.

![alt text](forest.png)


### EntraÃ®nement vs Ã©valuation : pourquoi on dÃ©coupe les donnÃ©es

Pour que le modÃ¨le apprenne et quâ€™on puisse mesurer sâ€™il est vraiment bon, on sÃ©pare les donnÃ©es en deux morceaux :

- **X_train** et **y_train** : ce sont les entrÃ©es (X_train) et les bonnes rÃ©ponses (y_train) que le modÃ¨le voit pendant **lâ€™entraÃ®nement**. Câ€™est lÃ  quâ€™il apprend les rÃ¨gles Ã  partir des exemples.
    
- **X_test** et **y_test** : ce sont des donnÃ©es **nouvelles**, que le modÃ¨le **nâ€™a pas vues** pendant lâ€™entraÃ®nement. On les utilise pour **Ã©valuer** sa capacitÃ© Ã  gÃ©nÃ©raliser â€” autrement dit, pour vÃ©rifier quâ€™il ne fait pas que Â« mÃ©moriser Â» mais quâ€™il sait bien prÃ©dire sur du neuf.
    

> En rÃ©sumÃ© : on entraÃ®ne avec `X_train`/`y_train`, on teste avec `X_test`/`y_test`. Cela permet de savoir si le modÃ¨le fonctionne vraiment et pas seulement sur les exemples quâ€™on lui a montrÃ©s.
### InterprÃ©tation des rÃ©sultats du modÃ¨le Ã  lâ€™aide de la matrice de confusion

La **matrice de confusion** est un tableau qui compare ce que le modÃ¨le a **prÃ©dit** avec ce qui Ã©tait **vraiment vrai**.  
Chaque ligne correspond Ã  la classe vraie, chaque colonne Ã  la classe prÃ©dite. Lâ€™idÃ©e : voir non seulement combien de prÃ©dictions Ã©taient correctes, mais _dans quel sens_ les erreurs ont Ã©tÃ© faites.
On voit **non seulement que le modÃ¨le est bon**, mais aussi **quel type dâ€™erreur il fait**.

Ici dans notre cas on peut noter : 
- **PrÃ©cision globale Ã©levÃ©e** : la majoritÃ© des Ã©chantillons ont Ã©tÃ© correctement classÃ©s.
    
- Le modÃ¨le a :
    
    - correctement identifiÃ© **85/86** laits de qualitÃ© `low`,
	    - **1 a Ã©tÃ© confondu avec `high`**. Autrement dit, un lait mauvais a Ã©tÃ© jugÃ© comme bon â€” câ€™est une erreur Ã  surveiller car câ€™est une fausse alarme inverse (faux nÃ©gatif sur `low` vu du point de vue de `high`).
        
    - parfaitement reconnu les **75/75** laits `medium`,
        
    - correctement classÃ© **51/51** laits `high`.

![[Pasted image 20250731130051.png]](confusion.png)


## AmÃ©lioration : optimisation du modÃ¨le actuel

Le modÃ¨le fonctionne dÃ©jÃ  trÃ¨s bien (â‰ˆ99 % de prÃ©cision), mais il utilise **7 features** pour faire sa prÃ©diction.  
Or, dans certains contextes (embarquÃ©, temps rÃ©el, coÃ»t de collecte des donnÃ©es), **rÃ©duire le nombre de variables** tout en gardant une prÃ©cision Ã©levÃ©e est une optimisation trÃ¨s utile : on diminue la complexitÃ©, on accÃ©lÃ¨re les infÃ©rences, et on simplifie la maintenance.

**Quelles sont les variables les plus importantes ?**

Le graphique ci-dessous reprÃ©sente **lâ€™importance des variables** utilisÃ©es par le modÃ¨le Random Forest pour prÃ©dire la qualitÃ© du lait..
- Chaque barre correspond Ã  une **caractÃ©ristique du lait**.
    
- La **longueur de la barre** indique Ã  quel point cette caractÃ©ristique a Ã©tÃ© **utile pour prendre des dÃ©cisions** dans les arbres du modÃ¨le.

| Rang      | Variable                                       | InterprÃ©tation                                                                                                                                             |
| --------- | ---------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1ï¸âƒ£       | **pH**                                         | Câ€™est la variable la plus influente. Un certain seuil de pH semble Ãªtre un indicateur fort de la qualitÃ© du lait.                                          |
| 2ï¸âƒ£       | **Temperature**                                | La tempÃ©rature est Ã©galement trÃ¨s discriminante, sans doute liÃ©e Ã  la conservation ou Ã  la fraÃ®cheur du lait.                                              |
| 3ï¸âƒ£       | **Fat**                                        | Le taux de matiÃ¨re grasse joue un rÃ´le significatif dans la distinction entre les catÃ©gories.                                                              |
| 4ï¸âƒ£ Ã  7ï¸âƒ£ | **Turbidity**, **Odor**, **Colour**, **Taste** | Ces variables ont un impact plus faible dans les dÃ©cisions du modÃ¨le. Elles apportent sans doute des nuances utiles, mais sont moins dÃ©terminantes seules. |


![[Pasted image 20250731130337.png]](variable.png)

RÃ©duction des features : compromis prÃ©cision vs simplicitÃ©

En relanÃ§ant lâ€™entraÃ®nement avec **100 arbres** mais en ne gardant que les trois variables les plus importantes (`pH`, `Temperature`, `Fat`), on obtient cette comparaison :

| Jeu de variables           | Accuracy | Perte par rapport au complet |
| -------------------------- | -------- | ---------------------------- |
| **Toutes les variables**   | 0.998    | â€”                            |
| **pH + Temperature + Fat** | 0.942    | â‰ˆ âˆ’6 points                  |

> Garder uniquement ces trois features permet dâ€™obtenir un modÃ¨le beaucoup plus lÃ©ger tout en conservant une prÃ©cision Ã©levÃ©e (~94 %). Câ€™est un compromis raisonnable : on sacrifie environ 6 points de performance pour simplifier la collecte des donnÃ©es, accÃ©lÃ©rer lâ€™infÃ©rence et amÃ©liorer lâ€™explicabilitÃ©.

Il reste maintenant Ã  dÃ©cider, en fonction du contexte de dÃ©ploiement (contraintes de calcul, coÃ»t des capteurs, exigence de prÃ©cision), si cette simplification vaut la lÃ©gÃ¨re baisse de performance.

##  DÃ©ploiement lÃ©ger : prÃ©diction dans Google Sheets (no-code light)

Pour rendre la prÃ©diction de la qualitÃ© du lait accessible sans infrastructure lourde, on a construit une version **light**, directement exploitable dans **Google Sheets**, qui repose uniquement sur les trois variables les plus influentes : **pH**, **Temperature** et **Fat**. Lâ€™idÃ©e nâ€™est pas de rÃ©pliquer exactement la Random Forest, mais dâ€™approximer sa logique avec une **rÃ¨gle pondÃ©rÃ©e** simple et interprÃ©table. 

### Comment Ã§a marche

1. **Score par variable** :  
    Chaque mesure est transformÃ©e en un score entre 0 et 1 selon sa proximitÃ© dâ€™une plage â€œidÃ©aleâ€ :
    
    - **pH** : idÃ©al entre 6,5 et 6,8.
        
    - **Temperature** : idÃ©al entre 35 et 45 Â°C.
        
    - **Fat** : 1 signifie matiÃ¨re grasse Ã©levÃ©e (bonne).
        
2. **Combinaison pondÃ©rÃ©e** :  
    On recombine ces trois scores en tenant compte de leur importance relative issue de la Random Forest :
    
    - pH : 53 %
        
    - Temperature : 32 %
        
    - Fat : 15 %  
        Le score global est donc une moyenne pondÃ©rÃ©e qui reflÃ¨te ce que le modÃ¨le â€œvoitâ€ comme signal fort.
        
3. **DÃ©cision** :  
    En fonction du score pondÃ©rÃ©, on classe lâ€™Ã©chantillon en `high`, `medium` ou `low`. Des seuils simples (par exemple â‰¥0,7 = high, â‰¥0,5 = medium, sinon low) permettent dâ€™avoir une prÃ©diction rapide et comprÃ©hensible.
    
4. **Alerte** :  
    Si au moins deux des trois variables principales sont hors de leur plage idÃ©ale, une fenÃªtre â€œVÃ©rifierâ€ sâ€™active pour signaler un contrÃ´le manuel.
    

![[Pasted image 20250731142401.png]](sheet.png)

# Conclusion

En parcourant lâ€™ensemble du workflow **machine learning**, nous avons dÃ©montrÃ© quâ€™il est possible de bÃ¢tir, Ã  partir de simples mesures physico-chimiques et sensorielles, un modÃ¨le de prÃ©diction **rapide, fiable et explicable** pour la qualitÃ© du lait. 

AprÃ¨s exploration, prÃ©paration des donnÃ©es et expÃ©rimentation de plusieurs variantes, la **Random Forest** sâ€™est avÃ©rÃ©e la plus performante : avec seulement trois variables : `pH`, `Temperature` et `Fat`,  elle atteint **94 % de prÃ©cision** tout en restant lÃ©gÃ¨re Ã  dÃ©ployer.

ğŸ¥› **Recommandations aux producteurs de lait**

- **Surveiller en prioritÃ© le pH et la tempÃ©rature** : ces deux mesures expliquent Ã  elles seules lâ€™essentiel des variations de qualitÃ©.
- **Former le personnel** Ã  lâ€™interprÃ©tation des prÃ©dictions : un outil de scoring nâ€™est utile que si les opÃ©rateurs savent en tirer des actions concrÃ¨tes (rÃ©glage de tempÃ©rature, tri de lots, nettoyage de ligne).

Variables prioritaires (top 3)

|Variable|Valeur cible / plage|Pourquoi câ€™est important|
|---|---|---|
|**pH**|6,5 â€“ 6,8|Meilleure discrimination de qualitÃ©. Valeurs hors intervalle = alerte.|
|**Temperature**|35â€“45 Â°C (analyse) / <4 Â°C (stockage)|Indicateur de fraÃ®cheur et sÃ©curitÃ© microbiologique.|
|**Fat**|1 (Ã©levÃ© dans ce dataset)|Influence directe du goÃ»t et perception de richesse.|
  
---

<div style="text-align: center;">

**Ne ratez plus aucune nouveautÃ© : abonnez-vous Ã  la newsletter ğŸ‘‹**

<form action="https://formspree.io/f/xwpkgwjd" method="POST" style="display:inline-block;">

Â  <label for="email" style="display:block; margin-bottom:0.5rem;">Votre email :</label>
Â  <input type="email" name="email" id="email" placeholder="exemple@domaine.com" required style="margin-bottom:0.5rem;">

Â  <button type="submit">Envoyer</button>
</form>
</div>

---

# Sources

- **Jeu de donnÃ©es â€“ PrÃ©diction de la qualitÃ© du lait**  
  [Milk Quality Prediction â€“ Kaggle](https://www.kaggle.com/datasets/cpluzshrijayan/milkquality)

- **Feuille de route â€“ Cheat Sheet du projet**  
  [Google Sheet â€“ Workflow & logique Machine Learning](https://docs.google.com/spreadsheets/d/1sYr5gzNDJyGrXJHyWE9kadEQYA8IlG0DcVmru-fceMY/edit?usp=sharing)

--- 

